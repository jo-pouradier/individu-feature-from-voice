{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install tensorflow\n",
    "!pip install tensorboard"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:48:35.786670Z",
     "start_time": "2024-12-09T15:48:35.781517Z"
    }
   },
   "source": [
    "data_path = r\"D:\\datasets\\cv-corpus-19.0-2024-09-13-fr\\cv-corpus-19.0-2024-09-13\\fr\"\n",
    "data_path = r\"/mnt/d/datasets/cv-corpus-19.0-2024-09-13-fr/cv-corpus-19.0-2024-09-13/fr\"\n",
    "\n",
    "train_age_only = True\n",
    "use_ordinal_age = False\n",
    "use_early_stopping = False\n",
    "features_length = 40\n",
    "\n",
    "# Hyperparameters\n",
    "loss_age_weight = 1\n",
    "loss_genre_weight = 0.1\n",
    "learning_rate = 0.00005\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "num_age_classes = 7\n",
    "train_ratio = 0.90"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def preprocess_label_data(label_data, keep_age=False):\n",
    "    gender_dict = {\n",
    "        'male_masculine': 0,\n",
    "        'female_feminine': 1\n",
    "    }\n",
    "    age_dict = {\n",
    "        'teens': 0,\n",
    "        'twenties': 1,\n",
    "        'thirties': 2,\n",
    "        'fourties': 3,\n",
    "        'fifties': 4,\n",
    "        'sixties': 5,\n",
    "        'seventies': 6\n",
    "    }\n",
    "    label_data = label_data.copy()\n",
    "    mfcc_features = []\n",
    "    for i in range(features_length):\n",
    "        mfcc_features.append(label_data[f'mfcc_{i}'])\n",
    "        label_data = label_data.drop(f'mfcc_{i}', axis=1)\n",
    "    label_data['mfcc_features'] = list(np.asarray(mfcc_features).T)\n",
    "    if use_ordinal_age:\n",
    "        label_data['age'] = label_data['age'].map(age_dict)\n",
    "    else:\n",
    "        dummies = pd.get_dummies(label_data['age'])\n",
    "        dummies = dummies[[*age_dict.keys()]]\n",
    "        label_data = pd.concat([label_data, dummies], axis=1)\n",
    "        if not keep_age:\n",
    "            label_data = label_data.drop('age', axis=1)\n",
    "    label_data['gender'] = label_data['gender'].map(gender_dict)\n",
    "    return label_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def load_csv_data(csv_path):\n",
    "    \"\"\"\n",
    "    Load CSV data into a DataFrame with specific columns.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_dataset(csv_path, batch_size, num_age_classes, train_ratio=0.8, random_state=0):\n",
    "    \"\"\"\n",
    "    Create a tf.data.Dataset from a CSV file.\n",
    "    \"\"\"\n",
    "    # Load CSV and preprocess\n",
    "    df = load_csv_data(csv_path)\n",
    "    df = preprocess_label_data(df)\n",
    "\n",
    "    # Split the data\n",
    "    train_data, val_data = train_test_split(df, train_size=train_ratio, random_state=random_state,\n",
    "                                            stratify=df['gender'])\n",
    "    print(f\"Train data: {len(train_data)} samples\")\n",
    "    print(f\"Validation data: {len(val_data)} samples\")\n",
    "\n",
    "    # Convert columns to tensors\n",
    "    def convert_to_tensors(data):\n",
    "        features = data['mfcc_features']\n",
    "        features = tf.convert_to_tensor(np.stack(features), dtype=tf.float32)\n",
    "        ages = tf.convert_to_tensor(data['age'] if use_ordinal_age else data.iloc[:, 4:].values,\n",
    "                                    dtype=tf.float32)  # Assuming age columns start from index 3\n",
    "        if not train_age_only:\n",
    "            genders = tf.convert_to_tensor(data['gender'].values, dtype=tf.int32)\n",
    "            return features, genders, ages\n",
    "        else:\n",
    "            return features, ages\n",
    "\n",
    "    if not train_age_only:\n",
    "        train_features, train_genders, train_ages = convert_to_tensors(train_data)\n",
    "        val_features, val_genders, val_ages = convert_to_tensors(val_data)\n",
    "        # Create datasets from tensors\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_genders, train_ages))\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((val_features, val_genders, val_ages))\n",
    "        # Parse rows, and batch\n",
    "        train_dataset = (\n",
    "            train_dataset\n",
    "            .map(lambda path, gender, age: tf_parse_row(path, gender, age, num_age_classes),\n",
    "                 num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE)  # Prefetch for efficient data loading\n",
    "        )\n",
    "\n",
    "        val_dataset = (\n",
    "            val_dataset\n",
    "            .map(lambda path, gender, age: tf_parse_row(path, gender, age, num_age_classes),\n",
    "                 num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE)  # Prefetch for efficient data loading\n",
    "        )\n",
    "    else:\n",
    "        train_features, train_ages = convert_to_tensors(train_data)\n",
    "        val_features, val_ages = convert_to_tensors(val_data)\n",
    "        # Create datasets from tensors\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_ages))\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((val_features, val_ages))\n",
    "\n",
    "        # Parse rows, and batch\n",
    "        train_dataset = (\n",
    "            train_dataset\n",
    "            .map(lambda features, age: tf_parse_row(features, None, age, num_age_classes),\n",
    "                 num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE)  # Prefetch for efficient data loading\n",
    "        )\n",
    "\n",
    "        val_dataset = (\n",
    "            val_dataset\n",
    "            .map(lambda features, age: tf_parse_row(features, None, age, num_age_classes),\n",
    "                 num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE)  # Prefetch for efficient data loading\n",
    "        )\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "def tf_parse_row(features, gender_label, age_label, num_age_classes):\n",
    "    \"\"\"\n",
    "    Wrapper to use the parse_row function with TensorFlow.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set shapes for TensorFlow to understand\n",
    "    features.set_shape([features_length])  # Ajustez cette forme en fonction de vos donnÃ©es\n",
    "    age_label.set_shape([] if use_ordinal_age else [num_age_classes])\n",
    "    labels = {\"age\": age_label}\n",
    "    if not train_age_only:\n",
    "        gender_label.set_shape([])\n",
    "        labels['gender'] = gender_label\n",
    "    return features, labels\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "csv_path = f\"features.csv\"\n",
    "train_dataset, val_dataset = create_dataset(csv_path, batch_size, num_age_classes, train_ratio)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:48:44.785452Z",
     "start_time": "2024-12-09T15:48:44.773736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, initializers\n",
    "\n",
    "\n",
    "class ConvBlock(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides=1, padding='same', activation='relu',\n",
    "                 kernel_initializer='he_normal', batch_norm=True, max_pool=True, dropout_rate=0.0):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            kernel_initializer=kernel_initializer\n",
    "        )\n",
    "        self.conv2 = layers.Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            kernel_initializer=kernel_initializer\n",
    "        )\n",
    "        self.batch_norm = layers.BatchNormalization() if batch_norm else None\n",
    "        self.activation = layers.Activation(activation)\n",
    "        self.max_pool = layers.MaxPooling1D(pool_size=2, strides=2, padding='same') if max_pool else None\n",
    "        self.dropout = layers.Dropout(dropout_rate) if dropout_rate > 0 else None\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.conv1(inputs, training=training)\n",
    "        x = self.conv2(x, training=training)\n",
    "        if self.batch_norm:\n",
    "            x = self.batch_norm(x, training=training)\n",
    "        x = self.activation(x)\n",
    "        if self.max_pool:\n",
    "            x = self.max_pool(x)\n",
    "        if self.dropout:\n",
    "            x = self.dropout(x, training=training)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AudioAgeAndGenderClassifier(tf.keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AudioAgeAndGenderClassifier, self).__init__(*args, **kwargs)\n",
    "        self.blocks = [\n",
    "            # ConvBlock(filters=16, kernel_size=3, strides=1, padding='same', activation='relu',\n",
    "            #           kernel_initializer='he_normal', batch_norm=False, max_pool=True, dropout_rate=0.0),\n",
    "            ConvBlock(filters=32, kernel_size=3, strides=1, padding='same', activation='relu',\n",
    "                      kernel_initializer='he_normal', batch_norm=False, max_pool=True, dropout_rate=0.0),\n",
    "            ConvBlock(filters=64, kernel_size=3, strides=1, padding='same', activation='relu',\n",
    "                      kernel_initializer='he_normal', batch_norm=False, max_pool=True, dropout_rate=0.1),\n",
    "            ConvBlock(filters=128, kernel_size=3, strides=1, padding='same', activation='relu',\n",
    "                      kernel_initializer='he_normal', batch_norm=False, max_pool=True, dropout_rate=0.1),\n",
    "            ConvBlock(filters=256, kernel_size=3, strides=1, padding='same', activation='relu',\n",
    "                      kernel_initializer='he_normal', batch_norm=True, max_pool=True, dropout_rate=0.2),\n",
    "            ConvBlock(filters=512, kernel_size=3, strides=1, padding='same', activation='relu',\n",
    "                      kernel_initializer='he_normal', batch_norm=True, max_pool=True, dropout_rate=0.2),\n",
    "        ]\n",
    "\n",
    "        self.reduction_layer = layers.Flatten()\n",
    "        self.dense = layers.Dense(128, activation='relu')\n",
    "        self.age_output = layers.Dense(1 if use_ordinal_age else num_age_classes,\n",
    "                                       activation=\"relu\" if use_ordinal_age else 'softmax')\n",
    "        if not train_age_only:\n",
    "            self.gender_output = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = tf.expand_dims(inputs, axis=-1)\n",
    "        # x = inputs\n",
    "        for block in self.blocks:\n",
    "            x = block(x, training=training)\n",
    "\n",
    "        x = self.reduction_layer(x)\n",
    "        x = self.dense(x, training=training)\n",
    "        age_pred = self.age_output(x)\n",
    "\n",
    "        if not train_age_only:\n",
    "            gender_pred = self.gender_output(x)\n",
    "            return {\"age\": age_pred, \"gender\": gender_pred}\n",
    "        else:\n",
    "            return {\"age\": age_pred}\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name:\n",
    "    print(f\"Using GPU: {device_name}\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733759324.781949  176862 gpu_device.cc:2022] Created device /device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:48:49.872135Z",
     "start_time": "2024-12-09T15:48:45.958656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "def age_loss_function(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Compile the model\n",
    "def compile_model(model, learning_rate=0.001):\n",
    "    # Define separate losses for age and gender\n",
    "    losses = {\n",
    "        \"age\": age_loss_function if use_ordinal_age else tf.keras.losses.CategoricalCrossentropy(),\n",
    "    }\n",
    "    metrics = {\n",
    "        \"age\": [\n",
    "            tf.keras.metrics.MeanSquaredError() if use_ordinal_age else tf.keras.metrics.CategoricalAccuracy,\n",
    "            # *[tf.keras.metrics.Recall(class_id=i, name=f'{i}') for i in range(num_age_classes)]\n",
    "        ],\n",
    "    }\n",
    "    if not train_age_only:\n",
    "        losses[\"gender\"] = tf.keras.losses.BinaryCrossentropy()\n",
    "        metrics[\"gender\"] = [tf.keras.metrics.BinaryAccuracy()]\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=losses,\n",
    "        loss_weights=[loss_age_weight, loss_genre_weight] if not train_age_only else [loss_age_weight],\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_test_classes, y_pred_classes, display_labels, title=\"Confusion Matrix\"):\n",
    "    plt.figure(figsize=(3, 1))\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "    # Optionally normalize the confusion matrix\n",
    "    # cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    # Display the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "    # Plot the matrix\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def retrieve_labels(dataset):\n",
    "    all_labels = []\n",
    "    for features, labels in dataset:\n",
    "        all_labels.append(labels)\n",
    "    print(np.asarray(all_labels).shape)\n",
    "    return np.concatenate(all_labels, axis=0)\n",
    "\n",
    "\n",
    "def print_example_output(model, dataset):\n",
    "    # Get the model predictions\n",
    "    predictions = {\"age\": [], \"gender\": []}\n",
    "    labels = {\"age\": [], \"gender\": []}\n",
    "    for features, labels_ in dataset:\n",
    "        for key in labels_.keys():\n",
    "            predictions[key].extend(model(features)[key].numpy())\n",
    "            labels[key].extend(labels_[key].numpy())\n",
    "    if not use_ordinal_age:\n",
    "        predictions[\"age\"] = np.argmax(predictions[\"age\"], axis=1)\n",
    "        labels[\"age\"] = np.argmax(labels[\"age\"], axis=1)\n",
    "    labels_names = ['teens', 'twenties',\n",
    "                    'thirties', 'fourties',\n",
    "                    'fifties', 'sixties',\n",
    "                    'seventies']\n",
    "    plot_confusion_matrix(labels[\"age\"], predictions[\"age\"],labels_names,\n",
    "                          title=\"Age Confusion Matrix\")\n",
    "\n",
    "    # precisions, recall, f1_score, _ = sklearn.metrics.precision_recall_fscore_support(labels[\"age\"], predictions[\"age\"])\n",
    "    # for i in range(num_age_classes):\n",
    "    #     print(f\"Age {i + 1}: Precision: {precisions[i]}, Recall: {recall[i]}, F1 Score: {f1_score[i]}\")\n",
    "\n",
    "    if not train_age_only:\n",
    "        predictions[\"gender\"] = predictions[\"gender\"] > 0.5\n",
    "        plot_confusion_matrix(labels[\"gender\"], predictions[\"gender\"], ['male', 'female'],\n",
    "                              title=\"Gender Confusion Matrix\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, dataset, validation_dataset, epochs, batch_size, verbose=0, print_confusion_matrix=True):\n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            \"train/best_model.weights.h5\", save_best_only=True, monitor=\"val_loss\", save_weights_only=True\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=\"./logs\"),\n",
    "    ]\n",
    "    if print_confusion_matrix:\n",
    "        callbacks.append(\n",
    "            tf.keras.callbacks.LambdaCallback(\n",
    "                on_epoch_end=lambda epoch, logs: print_example_output(model, val_dataset)\n",
    "            )\n",
    "        )\n",
    "    if use_early_stopping:\n",
    "        callbacks.append(\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\", patience=3\n",
    "            ), )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        dataset,\n",
    "        # validation_data=validation_dataset,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "csv_path = f\"{data_path}/features.csv\"\n",
    "\n",
    "train_dataset, val_dataset = create_dataset(csv_path, batch_size, num_age_classes, train_ratio)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 131031 samples\n",
      "Validation data: 14559 samples\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-09T15:48:49.877233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "model = AudioAgeAndGenderClassifier()\n",
    "model = compile_model(model, learning_rate)\n",
    "history = train_model(model, train_dataset, val_dataset, epochs, batch_size, verbose=2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = AudioAgeAndGenderClassifier()\n",
    "model = compile_model(model, learning_rate)\n",
    "# retrieve the best weights from the training folder\n",
    "# model.load_weights(\"train/model_epoch_31.weights.h5\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(20):\n",
    "    new_history = train_model(model, train_dataset, val_dataset, 2, batch_size, verbose=2, print_confusion_matrix=False)\n",
    "    for key in history.history.keys():\n",
    "        history.history[key] += new_history.history[key]\n",
    "    print_example_output(model, val_dataset)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot confusion matrix\n",
    "print_example_output(model, val_dataset)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualise a batch on the same figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features, labels = train_dataset.take(1).as_numpy_iterator().next()\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, feature in enumerate(features):\n",
    "    if i != 5:\n",
    "        continue\n",
    "    plt.plot(feature)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
